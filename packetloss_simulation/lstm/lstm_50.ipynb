{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "data_list = list()\n",
    "\n",
    "for i in range (155,255):\n",
    "    with open (f'../datafile_new/datafile{i}.txt') as _f:\n",
    "        data = _f.read().split('\\n')\n",
    "        _d = data[1:-1]\n",
    "    \n",
    "    data_list.extend(_d)\n",
    "\n",
    "final_list = list()\n",
    "for i in range (int(len(data_list)/100)):\n",
    "    _d = data_list[100*(i-1) : 100*i]\n",
    "    loss_packets = len([_data for _data in _d if _data == 'None'])\n",
    "    final_list.append(loss_packets)\n",
    "final_list = np.array(final_list)\n",
    "print(len(final_list))\n",
    "\n",
    "\n",
    "dataset = final_list.astype(np.float32)\n",
    "max_value = np.max(dataset)\n",
    "min_value = np.min(dataset)\n",
    "scalar = max_value - min_value\n",
    "dataset = list(map(lambda x: x / scalar, dataset))\n",
    "n = 2\n",
    "\n",
    "def create_dataset(dataset, look_back=n):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# 创建好输入输出\n",
    "data_X, data_Y = create_dataset(dataset)\n",
    "\n",
    "train_size = int(len(data_X) * 0.7)\n",
    "test_size = len(data_X) - train_size\n",
    "train_X = data_X[:train_size]\n",
    "train_Y = data_Y[:train_size]\n",
    "test_X = data_X[train_size:]\n",
    "test_Y = data_Y[train_size:]\n",
    "\n",
    "train_X = train_X.reshape(-1, 1, n)\n",
    "train_Y = train_Y.reshape(-1, 1, 1)\n",
    "test_X = test_X.reshape(-1, 1, n)\n",
    "\n",
    "train_x = torch.from_numpy(train_X)\n",
    "train_y = torch.from_numpy(train_Y)\n",
    "\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "test_loss = list()\n",
    "class lstm(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,num_layer):\n",
    "        super(lstm,self).__init__()\n",
    "        self.layer1 = nn.LSTM(input_size,hidden_size,num_layer)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.layer2 = nn.Linear(hidden_size,output_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x,_ = self.layer1(x)\n",
    "        x = self.dropout(x)\n",
    "        s,b,h = x.size()\n",
    "        x = x.view(s*b,h)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(s,b,-1)\n",
    "        return x\n",
    "output = 2\n",
    "model = lstm(n,4,2,3)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "# 开始训练\n",
    "for e in range(500):\n",
    "    var_x = Variable(train_x)\n",
    "    var_y = Variable(train_y)\n",
    "    # 前向传播\n",
    "    out = model(var_x)\n",
    "    loss = criterion(out, var_y)\n",
    "    pred = out.argmax(dim=1)\n",
    "\n",
    "    num_correct = 1\n",
    "    num_correct = torch.eq(pred, var_y).sum()\n",
    "    # 反向传播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (e + 1) % 1 == 0: # 每 100 次输出结果\n",
    "        print('Epoch: {}, Loss: {:.5f}'.format(e + 1, loss.item()))\n",
    "    test_loss.append(loss.item())\n",
    "\n",
    "torch.save(model, f'./packetloss_net_{n}.pkl')\n",
    "    \n",
    "model = model.eval() # 转换成测试模式\n",
    "\n",
    "data_X = data_X.reshape(-1, 1, n)\n",
    "data_X = torch.from_numpy(data_X)\n",
    "var_data = Variable(data_X)\n",
    "pred_test = model(var_data) # 测试集的预测结果\n",
    "# 改变输出的格式\n",
    "pred_test = pred_test.view(-1).data.numpy()\n",
    "# 画出实际结果和预测的结果\n",
    "plt.plot(pred_test, 'g', label='prediction')\n",
    "plt.plot(dataset, 'b', label='real')\n",
    "plt.legend(loc='best')\n",
    "plt.title('The graph of prediction and real dataset')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fontsize = {'size' : 15}\n",
    "plt.plot(test_loss)\n",
    "plt.xlabel('iterations', fontdict=fontsize)\n",
    "plt.ylabel('Mean Square Error', fontdict=fontsize)\n",
    "plt.title('MSE VS iterations', fontdict=fontsize)\n",
    "plt.savefig(f'output_prediction_step/{n}ahead/loss_iter.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_num in range (1, 40):\n",
    "    y_2 = int (30000 - n - 300 * (sample_num-1))\n",
    "    y_1 = y_2 - 300 + n + 10\n",
    "    print (y_1, y_2)\n",
    "    y = pred_test[y_1:y_2].tolist()\n",
    "    yy = list()\n",
    "    fontsize = {\n",
    "        'size': 20\n",
    "    }\n",
    "    cnt = 0\n",
    "    for _y in y:\n",
    "        if _y == max(y):\n",
    "            cnt = 1\n",
    "        if cnt == 1:\n",
    "            _y = max(y)\n",
    "\n",
    "        yy.append(_y)\n",
    "    del(y)\n",
    "    _y_2 = int (30000 - 300 * (sample_num-1))\n",
    "    _y_1 = _y_2 - 300 + 10\n",
    "    _y = dataset[_y_1:_y_2]\n",
    "    x = np.arange(0,len(_y)).tolist()\n",
    "    _x = np.arange(0,len(_y)).tolist()\n",
    "    plt.figure()\n",
    "    yy = [None] * n + yy\n",
    "    plt.plot(x, yy, 'g', label='prediction')\n",
    "    plt.plot(_x, _y, 'r', label='real')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.title('Prediction of packet loss rate', fontdict=fontsize)\n",
    "    plt.xlabel('number of time slots (time slot is 100s)', fontdict=fontsize)\n",
    "    plt.ylabel('packetloss rate / 100%',fontdict=fontsize)\n",
    "    plt.text(21, 0.3, f'Prediction made {n} slots ahead',fontdict={'size': 13})\n",
    "    plt.savefig(f'output_prediction_step/{n}ahead/test/packetloss_net_{sample_num}_{n}.png',dpi=300)\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    plt.plot(x, yy, 'g', label='prediction')\n",
    "    plt.plot(_x, _y, 'r', label='real')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.title('enlarged prediction area', fontdict=fontsize)\n",
    "    plt.xlim(250, 300)\n",
    "    plt.xticks(np.arange(250, 300, 5))\n",
    "    plt.grid()\n",
    "    plt.xlabel('number of time slots (time slot is 100s)', fontdict=fontsize)\n",
    "    plt.ylabel('packetloss rate / 100%',fontdict=fontsize)\n",
    "    plt.savefig(\n",
    "        f'output_prediction_step/{n}ahead/test_magnified/packetloss_net_{n}_magnified_sample\\{sample_num}.png',\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_pkloss = torch.load(f'./packetloss_net_{n}.pkl')\n",
    "\n",
    "with open (f'../datafile_new/datafile{2}.txt') as _f:\n",
    "        data = _f.read().split('\\n')\n",
    "        data_200 = data[1:-1]\n",
    "final_200 = list()\n",
    "for i in range (int(len(data_200)/100)):\n",
    "    _d = data_200[100*(i-1) : 100*i]\n",
    "    loss_packets = len([_data for _data in _d if _data == 'None'])\n",
    "    final_200.append(loss_packets)\n",
    "final_200 = np.array(final_200)\n",
    "\n",
    "dataset_200 = final_200.astype(np.float32)\n",
    "max_value = np.max(dataset_200)\n",
    "min_value = np.min(dataset_200)\n",
    "scalar = max_value - min_value\n",
    "dataset_200 = list(map(lambda x: x / scalar, dataset_200))\n",
    "model_pkloss.eval()\n",
    "X = np.array(dataset_200)\n",
    "X =X.reshape(-1, 1, n)\n",
    "print (X)\n",
    "data_200 = torch.from_numpy(X)\n",
    "var_200 = Variable(data_200)\n",
    "pred_test_200 = model(var_200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_200.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pred = np.array(pred_test_200.tolist())\n",
    "_orig = np.array(data_200)\n",
    "\n",
    "plot_table = {\n",
    "    'original': _orig,\n",
    "    'prediction': _pred\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_num in range (1,2):\n",
    "    model_pkloss = torch.load(f'./packetloss_net_{n}.pkl')\n",
    "\n",
    "    with open (f'../datafile_new/datafile{test_num}.txt') as _f:\n",
    "            data = _f.read().split('\\n')\n",
    "            data_200 = data[1:-1]\n",
    "    final_200 = list()\n",
    "    for i in range (int(len(data_200)/100)):\n",
    "        _d = data_200[100*(i-1) : 100*i]\n",
    "        loss_packets = len([_data for _data in _d if _data == 'None'])\n",
    "        final_200.append(loss_packets)\n",
    "    final_200 = np.array(final_200)\n",
    "\n",
    "    dataset_200 = final_200.astype(np.float32)\n",
    "    max_value = np.max(dataset_200)\n",
    "    min_value = np.min(dataset_200)\n",
    "    scalar = max_value - min_value\n",
    "    dataset_200 = list(map(lambda x: x / scalar, dataset_200))\n",
    "    X, Y = create_dataset(dataset_200)\n",
    "    print (n)\n",
    "    model_pkloss.eval()\n",
    "    X =X.reshape(-1, 1, n)\n",
    "    data_200 = torch.from_numpy(X)\n",
    "    var_200 = Variable(data_200)\n",
    "    print (len(var_200))\n",
    "    pred_test_200 = model(var_200)\n",
    "    pred_test_200 = pred_test_200.view(-1).data.numpy()\n",
    "\n",
    "    # 画出实际结果和预测的结果\n",
    "    pred_test_200 = [None] * n + list(pred_test)\n",
    "    plt.plot(pred_test_200, 'g', label='prediction')\n",
    "    plt.plot(dataset_200, 'b', label='real')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Generalization Test of model')\n",
    "    plt.xlabel('number of time-period (100s)')\n",
    "    plt.ylabel('rate of packet loss (*100%)')\n",
    "    plt.savefig(f'output_prediction_step/{n}ahead/Generalisation/Generalization test sample_{n}_{test_num}', dpi=300)\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
